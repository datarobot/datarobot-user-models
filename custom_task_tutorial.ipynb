{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4552ef1-39b6-4b32-bb8d-9df481c9d5e9",
   "metadata": {},
   "source": [
    "# Building, Testing, and Deploying a Custom Model\n",
    "\n",
    "This notebook walks through the general workflow for building a custom task. We'll also demonstrate how to then deploy your custom task to a cloud b\n",
    "\n",
    "## Note\n",
    "The final sections of this tutorial require that you have access to Cloud DataRobot (app.datarobot.com or app.eu.datarobot.com)\n",
    "\n",
    "## Agenda\n",
    "In this tutorial, we'll learn:\n",
    "1. How to create a custom task using simple python classes\n",
    "2. How to test your python class\n",
    "3. How to use the drum cli tools to test out your custom task \n",
    "4. How to use the DataRobot API to deploy your custom task to the DataRobot cloud for use in projects\n",
    "5. How to insert a custom task on the DataRobot cloud into a blueprint\n",
    "\n",
    "## Setup and Requirements [ In Progress]\n",
    "This tutorial assumes a few things about your filepath and prior work. \n",
    "\n",
    "**Firstly, you need a feature flag enabled:**\n",
    "\n",
    "Secondly, you should have a folder at the path `~/datarobot-user-models/`. If you put the folder in a different location, make sure you update the `TESTING_PATH` variable. This folder should contain 4 things:\n",
    "1. A folder containing your properly configured custom environment.     \n",
    "    In this example, it's named `public_dropin_environments/python3_pytorch/`\n",
    "    \n",
    "    \n",
    "2. A folder containing your properly-configured custom model.     \n",
    "    In this example, it's named `model_templates/python3_pytorch/`\n",
    "    \n",
    "    \n",
    "3. The current version of the DataRobot Python Client.\n",
    "    - Installation instructions for the client can be found here: [DataRobot Python Client Docs](https://datarobot-public-api-client.readthedocs-hosted.com/en/v2.20.0/setup/getting_started.html#installation)\n",
    "    - Full documentation for the client can be found here: [DataRobot Python Client Docs](https://datarobot-public-api-client.readthedocs-hosted.com/en/v2.20.0/index.html)\n",
    "\n",
    "\n",
    "4. A test dataset that you can use to test predictions from your custom model.     \n",
    "    In this example, it's stored at `tests/testdata/juniors_3_year_stats_regression.csv`\n",
    "\n",
    "It also assumes that you have access to app.datarobot.com.\n",
    "If you use another version of DataRobot - use appropriate credentials and URL.\n",
    "\n",
    "\n",
    "## Configuring Models and Environments\n",
    "For more information on how to properly configure custom models and environments, read the README of our [DataRobot User Models repository](https://github.com/datarobot/datarobot-user-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838b9ec-24b8-4307-b5e7-042ae8f0ba5d",
   "metadata": {},
   "source": [
    "# Building a custom task\n",
    "\n",
    "First, we need to import a few things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2f39ff-8382-494d-a085-e9d69515c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26180fa4-85f4-470c-ad85-ea83ac0fabbe",
   "metadata": {},
   "source": [
    "Now let's build a neural network! First we'll lay out the code, then we'll walk through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19999210-29c2-47a4-81a0-6625f173cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot_drum.custom_task_interfaces import RegressionEstimatorInterface\n",
    "\n",
    "class CustomTask(RegressionEstimatorInterface):\n",
    "    def create_regression_model(self, num_features: int) -> Sequential:\n",
    "        \"\"\"\n",
    "        Create a regression model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_features: int\n",
    "            Number of features in X to be trained with\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        model: Sequential\n",
    "            Compiled regression model\n",
    "        \"\"\"\n",
    "        input_dim, output_dim = num_features, 1\n",
    "\n",
    "        # create model\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(input_dim, activation=\"relu\", input_dim=input_dim, kernel_initializer=\"normal\"),\n",
    "                Dense(input_dim // 2, activation=\"relu\", kernel_initializer=\"normal\"),\n",
    "                Dense(output_dim, kernel_initializer=\"normal\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", \"mse\"])\n",
    "        return model\n",
    "\n",
    "\n",
    "    def build_regressor(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Make the regressor pipeline with the required preprocessor steps and estimator in the end.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: pd.DataFrame\n",
    "            X containing all the required features for training\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        regressor_pipeline: Pipeline\n",
    "            Regressor pipeline with preprocessor and estimator\n",
    "        \"\"\"\n",
    "\n",
    "        return KerasRegressor(\n",
    "            build_fn=self.create_regression_model,\n",
    "            num_features=len(X.columns),\n",
    "            epochs=20,\n",
    "            batch_size=8,\n",
    "            verbose=1,\n",
    "            validation_split=0.33,\n",
    "            callbacks=[EarlyStopping(patience=20)],\n",
    "        )\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, row_weights=None, **kwargs):\n",
    "        \"\"\" This hook defines how DataRobot will train this task.\n",
    "        DataRobot runs this hook when the task is being trained inside a blueprint.\n",
    "        As an output, this hook is expected to create an artifact containing a trained object, that is then used to predict new data.\n",
    "        The input parameters are passed by DataRobot based on project and blueprint configuration.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        X: pd.DataFrame\n",
    "            Training data that DataRobot passes when this task is being trained.\n",
    "        y: pd.Series\n",
    "            Project's target column.\n",
    "        row_weights: np.ndarray (optional, default = None)\n",
    "            A list of weights. DataRobot passes it in case of smart downsampling or when weights column is specified in project settings.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        CustomTask\n",
    "            returns an object instance of class CustomTask that can be used in chained method calls\n",
    "        \"\"\"\n",
    "        self.estimator = self.build_regressor(X)\n",
    "\n",
    "        tf.random.set_seed(1234)\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def save(self, artifact_directory):\n",
    "        \"\"\"\n",
    "        Serializes the object and stores it in `artifact_directory`\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        artifact_directory: str\n",
    "            Path to the directory to save the serialized artifact(s) to\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        # If your estimator is not pickle-able, you can serialize it using its native method,\n",
    "        # i.e. in this case for keras we use model.save, and then set the estimator to none\n",
    "        keras.models.save_model(self.estimator.model, Path(artifact_directory) / \"model\")\n",
    "        self.estimator.model = None\n",
    "\n",
    "        # Now that the estimator is none, it won't be pickled with the CustomTask class (i.e. this one)\n",
    "        with open(Path(artifact_directory) / \"artifact.pkl\", \"wb\") as fp:\n",
    "            pickle.dump(self, fp)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, artifact_directory):\n",
    "        \"\"\"\n",
    "        Deserializes the object stored within `artifact_directory`\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        cls\n",
    "            The deserialized object\n",
    "        \"\"\"\n",
    "\n",
    "        with open(Path(artifact_directory) / \"artifact.pkl\", \"rb\") as fp:\n",
    "            custom_task = pickle.load(fp)\n",
    "\n",
    "        custom_task.estimator.model = keras.models.load_model(Path(artifact_directory) / \"model\")\n",
    "\n",
    "        return custom_task\n",
    "\n",
    "    def predict(self, X, **kwargs):\n",
    "        \"\"\" This hook defines how DataRobot will use the trained object from fit() to transform new data.\n",
    "        DataRobot runs this hook when the task is used for scoring inside a blueprint.\n",
    "        As an output, this hook is expected to return the transformed data.\n",
    "        The input parameters are passed by DataRobot based on dataset and blueprint configuration.\n",
    "\n",
    "        Parameters\n",
    "        -------\n",
    "        X: pd.DataFrame\n",
    "            Data that DataRobot passes for transformation.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            Returns a dataframe with transformed data.\n",
    "        \"\"\"\n",
    "\n",
    "        return pd.DataFrame(data=self.estimator.predict(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9b5af-854b-4a8f-b174-6c58b7fa005e",
   "metadata": {},
   "source": [
    "There's a lot above, so don't worry about reading through it all now. The key idea is that we have several hooks, specifically fit, save, load, and predict. DataRobot will use these hooks automatically to run our custom task. Then we also have several helper functions, specifically build_regressor and create_regression_model. We could have just as easily defined a separate file with these helper functions and imported them (which is actually what the example does [here]), but since we're in a notebook it makes more sense to lay out everything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016bfbc-dc73-4f2e-a936-d6db6e4ccef7",
   "metadata": {},
   "source": [
    "Now let's actually use the class above. Since this is an ordinary python class, all we need to do is build an object and we can test it out to ensure our methods work! First, let's grab a dataset and then separate out the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8723510-6c27-4ece-8bfc-0e28921fef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tests/testdata/juniors_3_year_stats_regression.csv\")\n",
    "\n",
    "y = df['Grade 2014']\n",
    "X = df.drop(labels=['Grade 2014'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4c8c8-110d-464d-834b-c6560d230625",
   "metadata": {},
   "source": [
    "Now let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b4a1f57-c912-4ced-9bbe-fa7ab1cbc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = CustomTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82989943-c38f-403f-bc08-27b8370d59b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a889669-2be2-403d-985b-f62c4a61a9ca",
   "metadata": {},
   "source": [
    "TODO: emphasize that save is critically important. Maybe walk through what DataRobot will do and what it needs to work ?\n",
    "\n",
    "Since fit returns the estimator, we can use it to run save if we need to! This will create a serialized version of our model. Within DataRobot, this is how we hand off our model between the fit and predict hooks, which actually run in separate containers. In our code here we can test that out by saving our model, then loading it and running predict to make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea43b8ec-80f9-4b99-8eaf-f778aba66225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.CustomTask at 0x1864ef450>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.save(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5419aaa-ab0e-4bd9-bd54-918af84a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task.load(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ffeebdf-403e-4efb-a40c-4fc92af07c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185/185 [==============================] - 0s 430us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.767523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.769978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.650490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.763115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.636791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>28.275587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>27.721256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>32.391720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>24.609760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>32.922050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1477 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     28.767523\n",
       "1     27.769978\n",
       "2     28.650490\n",
       "3     25.763115\n",
       "4     30.636791\n",
       "...         ...\n",
       "1472  28.275587\n",
       "1473  27.721256\n",
       "1474  32.391720\n",
       "1475  24.609760\n",
       "1476  32.922050\n",
       "\n",
       "[1477 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8e275-f42a-42a4-b814-b70f1247223b",
   "metadata": {},
   "source": [
    "TODO: mention what they'll need to copy into custom.py (have a separate folder for this example so they can see the difference between notebook land and custom.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a855948-2cf5-4e0c-9bca-fac3b83d0c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drum_cli_enduser",
   "language": "python",
   "name": "drum_cli_enduser"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
