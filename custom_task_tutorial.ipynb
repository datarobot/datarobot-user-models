{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4552ef1-39b6-4b32-bb8d-9df481c9d5e9",
   "metadata": {},
   "source": [
    "# Building a Custom Task\n",
    "\n",
    "This notebook walks through the general workflow for building a custom task. We'll also demonstrate how to then deploy your custom task to a cloud b\n",
    "\n",
    "## Note\n",
    "The final sections of this tutorial require that you have access to Cloud DataRobot (app.datarobot.com or app.eu.datarobot.com)\n",
    "\n",
    "## Agenda\n",
    "In this tutorial, we'll learn:\n",
    "1. How to create a custom task using simple python classes\n",
    "2. How to test your python class\n",
    "3. How to use the drum cli tools to test out your custom task \n",
    "4. How to use the DataRobot API to deploy your custom task to the DataRobot cloud for use in projects\n",
    "5. How to insert a custom task on the DataRobot cloud into a blueprint\n",
    "\n",
    "## Setup and Requirements [ In Progress]\n",
    "This tutorial assumes a few things about your filepath and prior work. \n",
    "\n",
    "**Firstly, you need a feature flag enabled:**\n",
    "\n",
    "Secondly, you should have a folder at the path `~/datarobot-user-models/`. If you put the folder in a different location, make sure you update the `TESTING_PATH` variable. This folder should contain 4 things:\n",
    "1. A folder containing your properly configured custom environment.     \n",
    "    In this example, it's named `public_dropin_environments/python3_pytorch/`\n",
    "    \n",
    "    \n",
    "2. A folder containing your properly-configured custom model.     \n",
    "    In this example, it's named `model_templates/python3_pytorch/`\n",
    "    \n",
    "    \n",
    "3. The current version of the DataRobot Python Client.\n",
    "    - Installation instructions for the client can be found here: [DataRobot Python Client Docs](https://datarobot-public-api-client.readthedocs-hosted.com/en/v2.20.0/setup/getting_started.html#installation)\n",
    "    - Full documentation for the client can be found here: [DataRobot Python Client Docs](https://datarobot-public-api-client.readthedocs-hosted.com/en/v2.20.0/index.html)\n",
    "\n",
    "\n",
    "4. A test dataset that you can use to test predictions from your custom model.     \n",
    "    In this example, it's stored at `tests/testdata/juniors_3_year_stats_regression.csv`\n",
    "\n",
    "It also assumes that you have access to app.datarobot.com.\n",
    "If you use another version of DataRobot - use appropriate credentials and URL.\n",
    "\n",
    "\n",
    "## Configuring Models and Environments\n",
    "For more information on how to properly configure custom models and environments, read the README of our [DataRobot User Models repository](https://github.com/datarobot/datarobot-user-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838b9ec-24b8-4307-b5e7-042ae8f0ba5d",
   "metadata": {},
   "source": [
    "# Building a custom task\n",
    "\n",
    "First, we need to import a few things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e2f39ff-8382-494d-a085-e9d69515c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "\n",
    "import keras.models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26180fa4-85f4-470c-ad85-ea83ac0fabbe",
   "metadata": {},
   "source": [
    "Now let's build a neural network! First we'll lay out the code, then we'll walk through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19999210-29c2-47a4-81a0-6625f173cd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot_drum.custom_task_interfaces import RegressionEstimatorInterface\n",
    "\n",
    "class CustomTask(RegressionEstimatorInterface):\n",
    "    \n",
    "    def fit(self, X, y, row_weights=None, **kwargs):\n",
    "        tf.random.set_seed(1234)\n",
    "        input_dim, output_dim = len(X.columns), 1\n",
    "\n",
    "        model = Sequential(\n",
    "            [\n",
    "                Dense(\n",
    "                    input_dim, activation=\"relu\", input_dim=input_dim, kernel_initializer=\"normal\"\n",
    "                ),\n",
    "                Dense(input_dim // 2, activation=\"relu\", kernel_initializer=\"normal\"),\n",
    "                Dense(output_dim, kernel_initializer=\"normal\"),\n",
    "            ]\n",
    "        )\n",
    "        model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "        callback = EarlyStopping(monitor=\"loss\", patience=3)\n",
    "        model.fit(\n",
    "            X, y, epochs=20, batch_size=8, validation_split=0.33, verbose=1, callbacks=[callback]\n",
    "        )\n",
    "\n",
    "        # Attach the model to our object for future use\n",
    "        self.estimator = model\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def save(self, artifact_directory):\n",
    "\n",
    "        # If your estimator is not pickle-able, you can serialize it using its native method,\n",
    "        # i.e. in this case for keras we use model.save, and then set the estimator to none\n",
    "        keras.models.save_model(self.estimator, Path(artifact_directory) / \"model.h5\")\n",
    "\n",
    "        # Helper method to handle serializing, via pickle, the CustomTask class\n",
    "        self.save_task(artifact_directory, exclude=[\"estimator\"])\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, artifact_directory):\n",
    "        \n",
    "        # Helper method to load the serialized CustomTask class\n",
    "        custom_task = cls.load_task(artifact_directory)\n",
    "        custom_task.estimator = keras.models.load_model(Path(artifact_directory) / \"model.h5\")\n",
    "\n",
    "        return custom_task\n",
    "    \n",
    "\n",
    "    def predict(self, X, **kwargs):\n",
    "        # Note how the regression estimator only outputs one column, so no explicit column names are needed\n",
    "        return pd.DataFrame(data=self.estimator.predict(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9b5af-854b-4a8f-b174-6c58b7fa005e",
   "metadata": {},
   "source": [
    "There's a lot above, but the key idea is that we have 4 hooks: fit, save, load, and predict. DataRobot will use these hooks automatically to run our custom task. As you can probably guess, these hooks run in a specific order: first we train (fit) a model, then we serialize it (see the section [below]), then we load (i.e. deserialize) it again, and finally we then make predictions. \n",
    "\n",
    "One thing to note is that the above CustomTask is simply a python class, which means we can also add helper methods or have functions / classes in a helper file that we import. The more complex your CustomTask, the more it probably makes sense to import a separate helper file to keep things simple. See [here] for an example of directly using helper methods in the class and [here] for using a separate helper file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177d7dfa-e1d9-4ac7-bbd8-0f31e99db09b",
   "metadata": {},
   "source": [
    "## Training our model with Fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016bfbc-dc73-4f2e-a936-d6db6e4ccef7",
   "metadata": {},
   "source": [
    "Now let's actually use the class above. Since this is an ordinary python class, all we need to do is build an object and we can test it out to ensure our methods work! First, let's grab a dataset and then separate out the target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8723510-6c27-4ece-8bfc-0e28921fef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tests/testdata/juniors_3_year_stats_regression.csv\")\n",
    "\n",
    "y = df['Grade 2014']\n",
    "X = df.drop(labels=['Grade 2014'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e4c8c8-110d-464d-834b-c6560d230625",
   "metadata": {},
   "source": [
    "Now let's train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b4a1f57-c912-4ced-9bbe-fa7ab1cbc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = CustomTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82989943-c38f-403f-bc08-27b8370d59b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "124/124 [==============================] - 0s 2ms/step - loss: 243.6316 - mae: 11.2293 - mse: 243.6316 - val_loss: 127.8057 - val_mae: 7.8969 - val_mse: 127.8057\n",
      "Epoch 2/20\n",
      "124/124 [==============================] - 0s 945us/step - loss: 119.6218 - mae: 7.3784 - mse: 119.6218 - val_loss: 126.4541 - val_mae: 7.1894 - val_mse: 126.4541\n",
      "Epoch 3/20\n",
      "124/124 [==============================] - 0s 928us/step - loss: 119.6898 - mae: 7.4064 - mse: 119.6898 - val_loss: 131.0404 - val_mae: 6.7115 - val_mse: 131.0404\n",
      "Epoch 4/20\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 118.2549 - mae: 7.2968 - mse: 118.2549 - val_loss: 126.3128 - val_mae: 8.0251 - val_mse: 126.3128\n",
      "Epoch 5/20\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 118.4696 - mae: 7.3713 - mse: 118.4696 - val_loss: 124.3396 - val_mae: 7.1751 - val_mse: 124.3396\n",
      "Epoch 6/20\n",
      "124/124 [==============================] - 0s 1ms/step - loss: 119.1182 - mae: 7.2953 - mse: 119.1182 - val_loss: 129.7029 - val_mae: 6.6129 - val_mse: 129.7029\n",
      "Epoch 7/20\n",
      "124/124 [==============================] - 0s 965us/step - loss: 119.7277 - mae: 7.4162 - mse: 119.7277 - val_loss: 123.8151 - val_mae: 7.6164 - val_mse: 123.8151\n"
     ]
    }
   ],
   "source": [
    "task = task.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14e29fc-b5a3-4448-a9c5-f521f8c8244d",
   "metadata": {},
   "source": [
    "## Saving and Loading our Custom Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a889669-2be2-403d-985b-f62c4a61a9ca",
   "metadata": {},
   "source": [
    "You may be wondering why we need to save our model only to immediately load it again to make predictions. The reason is that model training and prediction, also known as inference or scoring, are distinct tasks that may have very different resource requirements. As an extreme example, one of DataRobot's proprietary models is a genetic algorithm known as Eureqa. Training this model can take some time, as it iterates through hundreds, thousands, or even millions of mathematical transformations. However the output of this model is a simple mathematical equation, which can run almost instantly on very modest computational resources. So during training we want to allocate a high amount of compute, but while the model is making predictions, e.g. it is deployed and waiting to receive new data, we want a far lower amount of compute allocated.  \n",
    "\n",
    "The way we achieve this is by using Docker containers, which we can think of as extremely lightweight virtual machines. This allows our training container to have significantly different computational resources allocated than our prediction container. But since the training and prediction steps are in separate containers, we need a way to move trained models and other useful artifacts, e.g. class labels, between them. The solution is to write out the artifacts to disk, i.e. serialize them. So our save method at the end of training will write out the model to a shared file storage location and then our load method at the beginning of making predictions will read the artifacts into memory, i.e. deserialize them. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea43b8ec-80f9-4b99-8eaf-f778aba66225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CustomTask at 0x18677de90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.save(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5419aaa-ab0e-4bd9-bd54-918af84a35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task.load(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ffeebdf-403e-4efb-a40c-4fc92af07c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27.046207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.635019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.916660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.292889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.178623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>24.894941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>26.109985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>31.427782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>23.208033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>31.082373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1477 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     27.046207\n",
       "1     25.635019\n",
       "2     26.916660\n",
       "3     25.292889\n",
       "4     28.178623\n",
       "...         ...\n",
       "1472  24.894941\n",
       "1473  26.109985\n",
       "1474  31.427782\n",
       "1475  23.208033\n",
       "1476  31.082373\n",
       "\n",
       "[1477 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12611cf-00f2-420c-b237-6ce09111cf45",
   "metadata": {},
   "source": [
    "Let's take a look more deeply at the save method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69f5d9ff-a732-4b4b-982b-3b7c98b543b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Serializes the object and stores it in `artifact_directory`\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "artifact_directory: str\n",
       "    Path to the directory to save the serialized artifact(s) to.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "self\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# If your estimator is not pickle-able, you can serialize it using its native method,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# i.e. in this case for keras we use model.save, and then set the estimator to none\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Helper method to handle serializing, via pickle, the CustomTask class\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"estimator\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /var/folders/zd/m7w2dbld2v9dlsdrtdrb1ms40000gq/T/ipykernel_58586/2228518297.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??task.save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df8a48-7dae-40ee-b007-16fcaa28bd38",
   "metadata": {},
   "source": [
    "As we can see, we use two distinct functions to save our model. First, we use the keras function save_model to save our self.estimator, i.e. the trained model from the fit function. Then we use a built in helper function, save_task. Let's look at save task quickly:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50e28c39-8f44-4ffb-a86c-6d74fe9008a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0msave_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
       "\u001b[0;34m        Helper function that abstracts away pickling the CustomTask object. It also can\u001b[0m\n",
       "\u001b[0;34m        automatically set previously serialized variables to None, e.g. when using keras you likely\u001b[0m\n",
       "\u001b[0;34m        want to serialize self.estimator using model.save() or keras.models.save_model() and then\u001b[0m\n",
       "\u001b[0;34m        pass in exclude='estimator'\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Parameters\u001b[0m\n",
       "\u001b[0;34m        ----------\u001b[0m\n",
       "\u001b[0;34m        artifact_directory: str\u001b[0m\n",
       "\u001b[0;34m            Path to the directory to save the serialized artifact(s) to.\u001b[0m\n",
       "\u001b[0;34m        exclude: List[str]\u001b[0m\n",
       "\u001b[0;34m            Variables on the CustomTask object we want to exclude from serialization by setting to None\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns\u001b[0m\n",
       "\u001b[0;34m        -------\u001b[0m\n",
       "\u001b[0;34m        None\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# If any custom task variables are excluded in the pickle, temporarily store them here, set them to None, then\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# restore them back onto the class after serialization\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvariables_to_restore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mcustom_task_variable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;31m# Ensure the variable actually exists in the custom task\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0mvariables_to_restore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustom_task_variable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_task_variable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;32mraise\u001b[0m \u001b[0mDrumCommonException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                        \u001b[0;34mf\"The object named {custom_task_variable} passed in exclude= was not found\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                    \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;31m# Set it to None so it does not get serialized\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_task_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSerializable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_artifact_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mcustom_task_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables_to_restore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_task_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/.virtualenvs/drum_1.6.6/lib/python3.7/site-packages/datarobot_drum/custom_task_interfaces/custom_task_interface.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??task.save_task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d003172-6a15-4a36-8f89-f39da5200894",
   "metadata": {},
   "source": [
    "Don't worry about understanding every line above. The key point is that we set everything passed in the exclude parameter to None, then we use a the standard python library pickle to serialize the CustomTask object. The reason we do this is flexibility. There are a wide array of python ML frameworks, e.g. keras / tensorflow, pytorch, xgboost, etc. Many of these frameworks, particularly those around neural networks, have their own serialization functions that handle all the complexities around storing weights, archiectures, etc. \n",
    "\n",
    "So the recommended pattern is to save your estimator using your framework's serialization function, e.g. keras.models.save_model above, and then use the helper function save_task we provide to save the rest of your CustomTask object. \n",
    "\n",
    "If we look at the load method, we see that we simply reverse the order. First we use the helper function load_task to load our CustomTask object using pickle, then we load our estimator into self.estimator using the keras function load_model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b8a6eb6-8bb5-4cbc-b0c0-659b3069c107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Deserializes the object stored within `artifact_directory`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "artifact_directory: str\n",
       "    Path to the directory to save the serialized artifact(s) to.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "cls\n",
       "    The deserialized object\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Helper method to load the serialized CustomTask class\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcustom_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcustom_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_directory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /var/folders/zd/m7w2dbld2v9dlsdrtdrb1ms40000gq/T/ipykernel_58586/2228518297.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??task.load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb8e275-f42a-42a4-b814-b70f1247223b",
   "metadata": {},
   "source": [
    "It's important to understand that some python ML frameworks, notably Sklearn, use pickle for their serialization as well. This means we don't need to write our own save / load functions in our CustomTask, as the default functions will simply pickle everyting including the model. The below example is from the template [here] and shows how this looks for a simple sklearn model. You can see that the whole CustomTask is around 10 lines of code. Pretty neat, huh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "961306ce-2a76-4f6a-b229-eb468507726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTask(RegressionEstimatorInterface):\n",
    "    def fit(self, X, y, row_weights=None, **kwargs):\n",
    "        \n",
    "        self.estimator = Ridge()\n",
    "        self.estimator.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, **kwargs):\n",
    "\n",
    "        return pd.DataFrame(data=self.estimator.predict(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff725e50-b847-471e-9d47-34f7dd1cdc72",
   "metadata": {},
   "source": [
    "## Making Predictions with the Correct Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98816191-ba64-433d-a11d-a3d5752bc405",
   "metadata": {},
   "source": [
    "A CustomTask currently has to output a pandas dataframe where the rows are the samples and the columns the predictions. \n",
    "\n",
    "As you may have noticed, all of examples so far have been regressors, i.e. outputting a single, numeric prediction. So our rows are just the number of samples and we have a single column (which doesn't need a specific name). We can see that our CustomTasks above inherit from the RegressionEstimatorInterface, which enforces this behavior.\n",
    "\n",
    "We can use the exact same behavior when we are creating an anomaly CustomTask, because the output is again a single numeric column representing how anomalous each sample is. There is a corresponding AnomalyEstimatorInterface\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6c045f-98f3-4a0b-8d5a-c5566b426c52",
   "metadata": {},
   "source": [
    "Things are a little trickier though when we need to create a binary or multiclass estimator. That's because we'll need to align the columns to the classes. Keep in mind that our CustomTask will run inside a DataRobot blueprint, which will be given a list of classes in the target. Let's take a look at an example binary estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f98e0b28-99ed-4f50-9cec-9f174c5b9300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot_drum.custom_task_interfaces import BinaryEstimatorInterface\n",
    "\n",
    "class CustomTask(BinaryEstimatorInterface):\n",
    "    def fit(self, X, y, row_weights=None, **kwargs):\n",
    "        \n",
    "        self.estimator = DecisionTreeClassifier()\n",
    "        self.estimator.fit(X, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X, **kwargs):\n",
    "\n",
    "        # Note that binary estimators require two columns in the output, the positive and negative class labels\n",
    "        # So we need to pass in the the class names derived from the estimator as column names OR\n",
    "        # we can use the class labels from DataRobot stored in\n",
    "        # kwargs['positive_class_label'] and kwargs['negative_class_label']\n",
    "        return pd.DataFrame(data=self.estimator.predict_proba(X), columns=self.estimator.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72145ce3-a5a3-4a79-a560-a6bd2dd06d66",
   "metadata": {},
   "source": [
    "The first thing to notice is that because we're outputting probabilities, we define a predict_proba instead of a predict function. The second thing to notice is that we have to provide the column names of our dataframe, and they have to align to the classes of our dataset. If you look at the fit function, you'll notice we directly pass in the target column y. This will have our target labels and these will be passed to our model as we train it, i.e. self.estimator.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87859af7-9def-4eac-b5e4-c85746cd330f",
   "metadata": {},
   "source": [
    "For binary classification, DataRobot requires there to be 2 columns: the positive class prediction and the negative class prediction \n",
    "(which is the inverse). Obviously, these two numbers should sum up to 1.0. \n",
    "\n",
    "For frameworks that output 2 classes, like sklearn, we cna simply use the classes stored by the sklearn model itself, i.e. self.estimator.classes_\n",
    "\n",
    "Some frameworks, such as pytorch, instead only output one column (typically the positive class probability). In those cases we have to derive the negative class column, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87d006f7-71d1-46ef-ba53-55c5fdea8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict_proba(self, X, **kwargs):\n",
    "        \"\"\"Since pytorch only outputs a single probability, i.e. the probability of the positive class,\n",
    "         we use the class labels passed in kwargs to label the columns\"\"\"\n",
    "        data_tensor = torch.from_numpy(X.values).type(torch.FloatTensor)\n",
    "        predictions = self.estimator(data_tensor).cpu().data.numpy()\n",
    "        \n",
    "        predictions = pd.DataFrame(predictions, columns=[kwargs[\"positive_class_label\"]])\n",
    "\n",
    "        # The negative class probability is just the inverse of what the model predicts above\n",
    "        predictions[kwargs[\"negative_class_label\"]] = (\n",
    "            1 - predictions[kwargs[\"positive_class_label\"]]\n",
    "        )\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2528c5b1-5bbd-4c02-878b-11d9c9f1cee2",
   "metadata": {},
   "source": [
    "Multiclass is slightly more challenging. Here we'll need to output the probability of each class as a separate column. If our framework stores. the classes, like many sklearn models, we can use the same exact same approach as above with binary classification. If the framework doesn't store the classes, e.g. pytorch, then we'll need to store the classes during the fit step on the self object so it can be used as the columns (NOTE: the save & load methods are excluded below to focus in on the unique aspects of multiclass):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9a46774-4c5d-46d6-995e-2cf423ebc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datarobot_drum.custom_task_interfaces import MulticlassEstimatorInterface\n",
    "\n",
    "\n",
    "class CustomTask(MulticlassEstimatorInterface):\n",
    "    def fit(self, X, y, row_weights=None, **kwargs):\n",
    "        \"\"\"Note how we encode the class labels and store them on self to be used in the predict hook\"\"\"\n",
    "        self.lb = LabelEncoder().fit(y)\n",
    "        y = self.lb.transform(y)\n",
    "\n",
    "        # For reproducible results\n",
    "        torch.manual_seed(0)\n",
    "\n",
    "        self.estimator, optimizer, criterion = build_classifier(X, len(self.lb.classes_))\n",
    "        train_classifier(X, y, self.estimator, optimizer, criterion)\n",
    "        \n",
    "\n",
    "    def predict_proba(self, X, **kwargs):\n",
    "        \"\"\"Note how the column names come from the encoded class labels in the fit hook above\"\"\"\n",
    "        data_tensor = torch.from_numpy(X.values).type(torch.FloatTensor)\n",
    "        predictions = self.estimator(data_tensor).cpu().data.numpy()\n",
    "\n",
    "        # Note that multiclass estimators require one column per class in the output\n",
    "        # So we need to pass in the the class names derived from the estimator as column names.\n",
    "        return pd.DataFrame(data=predictions, columns=self.lb.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff386820-c309-4d99-9243-2e51272817fa",
   "metadata": {},
   "source": [
    "## Transformers vs. Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc84954-0660-46e4-9263-8ca4b4aca0b5",
   "metadata": {},
   "source": [
    "So far we've focused on Estimators, which output a prediction. We can also create transforms, which manipulate the data and pass it along to (eventually) an estimator. Note: this final estimator can either be a built in DataRobot task or a CustomTask.\n",
    "\n",
    "The key difference between estimators and transforms is that instead of a predict function we have a transform function. The transform function also returns a dataframe, but instead of predictions it returns the transformed data. Note that while you can certainly create or remove columns, the transform function must output the same number of rows, e.g. you can't create new synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45714758-be06-4e9a-9bd2-1fce3c82a55e",
   "metadata": {},
   "source": [
    "## Understanding the CustomTask Interface (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4014a38c-5dbc-4fc9-a605-abb31de2e673",
   "metadata": {},
   "source": [
    "# How to upload a model via the web application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c7bd9-5dfa-4b72-9973-ef8aa33dc70d",
   "metadata": {},
   "source": [
    "TODO: mention what they'll need to copy into custom.py (have a separate folder for this example so they can see the difference between notebook land and custom.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868ac93-24ab-42a1-9103-ebbdd0e6ca51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drum_1.6.6",
   "language": "python",
   "name": "drum_1.6.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
