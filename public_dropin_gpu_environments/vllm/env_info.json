{
  "id": "662d6a54ef58f64c5a07d122",
  "name": "[GenAI] vLLM Inference Server",
  "description": "A high-throughput and memory-efficient inference and serving engine for LLMs.",
  "programmingLanguage": "python",
  "label": "v0.10.0",
  "environmentVersionId": "696049450659c7076da359db",
  "environmentVersionDescription": "Update to vllm v0.10.0\nFROM vllm/vllm-openai:v0.10.0",
  "isPublic": true,
  "isDownloadable": true,
  "useCases": [
    "customModel"
  ],
  "contextUrl": "https://github.com/datarobot/datarobot-user-models/tree/master/public_dropin_gpu_environments/vllm",
  "imageRepository": "env-gpu-vllm",
  "tags": [
    "v11.5.0-696049450659c7076da359db",
    "696049450659c7076da359db",
    "v11.5.0-latest"
  ]
}
