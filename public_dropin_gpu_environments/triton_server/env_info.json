{
  "id": "661516a0d53a8a537360dbd9",
  "name": "[NVIDIA] Triton Inference Server (24.01)",
  "description": "This template environment can be used to create artifact-only ONNX custom models. This environment contains ONNX runtime and only requires your model artifact as an .onnx file and optionally a custom.py file.",
  "programmingLanguage": "python",
  "environmentVersionId": "661925d7c1df095c96381218",
  "isPublic": true
}
