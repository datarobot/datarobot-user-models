name: NVIDIA NeMo Inference Server Example
type: inference
targetType: textgeneration

runtimeParameterDefinitions:
  - fieldName: s3Url
    type: string
    defaultValue: s3://nvidia-nim-model-repo/Llama-2-7b-chat-hf/24.02/A10-1x/
    description: Choose location of NIM compiled engine artifacts

  - fieldName: s3Credential
    type: credential
    description: AWS Access tokens to fetch model artifacts with

  - fieldName: max_tokens
    type: numeric
    defaultValue: 256
    description: max number of symbols in response
