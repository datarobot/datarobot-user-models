# -*- coding: utf-8 -*-
"""

Copyright 2020 xuannianz github user

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

THE FOLLOWING IS THE COPYRIGHT OF THE ORIGINAL DOCUMENT:
https://github.com/xuannianz/EfficientDet/blob/master/model.py
"""

from functools import reduce

import tensorflow as tf
from tensorflow.keras import layers
from tensorflow.keras import initializers
from tensorflow.keras import models
from tfkeras import EfficientNetB0, EfficientNetB1, EfficientNetB2
from tfkeras import EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6

from layers import ClipBoxes, RegressBoxes, FilterDetections, wBiFPNAdd, BatchNormalization
from initializers import PriorProbability
from object_detection_utils import anchors_for_shape
import numpy as np

w_bifpns = [64, 88, 112, 160, 224, 288, 384]
d_bifpns = [3, 4, 5, 6, 7, 7, 8]
d_heads = [3, 3, 3, 4, 4, 4, 5]
image_sizes = [512, 640, 768, 896, 1024, 1280, 1408]
backbones = [
    EfficientNetB0,
    EfficientNetB1,
    EfficientNetB2,
    EfficientNetB3,
    EfficientNetB4,
    EfficientNetB5,
    EfficientNetB6,
]

MOMENTUM = 0.997
EPSILON = 1e-4


def SeparableConvBlock(num_channels, kernel_size, strides, name, freeze_bn=False):
    f1 = layers.SeparableConv2D(
        num_channels,
        kernel_size=kernel_size,
        strides=strides,
        padding="same",
        use_bias=True,
        name=f"{name}/conv",
    )
    f2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name=f"{name}/bn")
    # f2 = BatchNormalization(freeze=freeze_bn, name=f'{name}/bn')
    return reduce(lambda f, g: lambda *args, **kwargs: g(f(*args, **kwargs)), (f1, f2))


def ConvBlock(num_channels, kernel_size, strides, name, freeze_bn=False):
    f1 = layers.Conv2D(
        num_channels,
        kernel_size=kernel_size,
        strides=strides,
        padding="same",
        use_bias=True,
        name="{}_conv".format(name),
    )
    f2 = layers.BatchNormalization(momentum=MOMENTUM, epsilon=EPSILON, name="{}_bn".format(name))
    # f2 = BatchNormalization(freeze=freeze_bn, name='{}_bn'.format(name))
    f3 = layers.ReLU(name="{}_relu".format(name))
    return reduce(lambda f, g: lambda *args, **kwargs: g(f(*args, **kwargs)), (f1, f2, f3))


def build_wBiFPN(features, num_channels, id, freeze_bn=False):
    if id == 0:
        _, _, C3, C4, C5 = features
        P3_in = C3
        P4_in = C4
        P5_in = C5
        P6_in = layers.Conv2D(
            num_channels, kernel_size=1, padding="same", name="resample_p6/conv2d"
        )(C5)
        P6_in = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name="resample_p6/bn"
        )(P6_in)
        # P6_in = BatchNormalization(freeze=freeze_bn, name='resample_p6/bn')(P6_in)
        P6_in = layers.MaxPooling2D(
            pool_size=3, strides=2, padding="same", name="resample_p6/maxpool"
        )(P6_in)
        P7_in = layers.MaxPooling2D(
            pool_size=3, strides=2, padding="same", name="resample_p7/maxpool"
        )(P6_in)
        P7_U = layers.UpSampling2D()(P7_in)
        P6_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode0/add")([P6_in, P7_U])
        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)
        P6_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode0/op_after_combine5",
        )(P6_td)
        P5_in_1 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode1/resample_0_2_6/conv2d",
        )(P5_in)
        P5_in_1 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn"
        )(P5_in_1)
        # P5_in_1 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn')(P5_in_1)
        P6_U = layers.UpSampling2D()(P6_td)
        P5_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode1/add")([P5_in_1, P6_U])
        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)
        P5_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode1/op_after_combine6",
        )(P5_td)
        P4_in_1 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode2/resample_0_1_7/conv2d",
        )(P4_in)
        P4_in_1 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn"
        )(P4_in_1)
        # P4_in_1 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn')(P4_in_1)
        P5_U = layers.UpSampling2D()(P5_td)
        P4_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode2/add")([P4_in_1, P5_U])
        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)
        P4_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode2/op_after_combine7",
        )(P4_td)
        P3_in = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode3/resample_0_0_8/conv2d",
        )(P3_in)
        P3_in = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn"
        )(P3_in)
        # P3_in = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn')(P3_in)
        P4_U = layers.UpSampling2D()(P4_td)
        P3_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode3/add")([P3_in, P4_U])
        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)
        P3_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode3/op_after_combine8",
        )(P3_out)
        P4_in_2 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode4/resample_0_1_9/conv2d",
        )(P4_in)
        P4_in_2 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn"
        )(P4_in_2)
        # P4_in_2 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn')(P4_in_2)
        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P3_out)
        P4_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode4/add")([P4_in_2, P4_td, P3_D])
        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)
        P4_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode4/op_after_combine9",
        )(P4_out)

        P5_in_2 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode5/resample_0_2_10/conv2d",
        )(P5_in)
        P5_in_2 = layers.BatchNormalization(
            momentum=MOMENTUM,
            epsilon=EPSILON,
            name=f"fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn",
        )(P5_in_2)
        # P5_in_2 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn')(P5_in_2)
        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P4_out)
        P5_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode5/add")([P5_in_2, P5_td, P4_D])
        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)
        P5_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode5/op_after_combine10",
        )(P5_out)

        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P5_out)
        P6_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode6/add")([P6_in, P6_td, P5_D])
        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)
        P6_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode6/op_after_combine11",
        )(P6_out)

        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P6_out)
        P7_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode7/add")([P7_in, P6_D])
        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)
        P7_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode7/op_after_combine12",
        )(P7_out)

    else:
        P3_in, P4_in, P5_in, P6_in, P7_in = features
        P7_U = layers.UpSampling2D()(P7_in)
        P6_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode0/add")([P6_in, P7_U])
        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)
        P6_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode0/op_after_combine5",
        )(P6_td)
        P6_U = layers.UpSampling2D()(P6_td)
        P5_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode1/add")([P5_in, P6_U])
        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)
        P5_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode1/op_after_combine6",
        )(P5_td)
        P5_U = layers.UpSampling2D()(P5_td)
        P4_td = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode2/add")([P4_in, P5_U])
        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)
        P4_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode2/op_after_combine7",
        )(P4_td)
        P4_U = layers.UpSampling2D()(P4_td)
        P3_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode3/add")([P3_in, P4_U])
        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)
        P3_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode3/op_after_combine8",
        )(P3_out)
        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P3_out)
        P4_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode4/add")([P4_in, P4_td, P3_D])
        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)
        P4_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode4/op_after_combine9",
        )(P4_out)

        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P4_out)
        P5_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode5/add")([P5_in, P5_td, P4_D])
        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)
        P5_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode5/op_after_combine10",
        )(P5_out)

        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P5_out)
        P6_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode6/add")([P6_in, P6_td, P5_D])
        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)
        P6_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode6/op_after_combine11",
        )(P6_out)

        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P6_out)
        P7_out = wBiFPNAdd(name=f"fpn_cells/cell_{id}/fnode7/add")([P7_in, P6_D])
        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)
        P7_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode7/op_after_combine12",
        )(P7_out)
    return P3_out, P4_td, P5_td, P6_td, P7_out


def build_BiFPN(features, num_channels, id, freeze_bn=False):
    if id == 0:
        _, _, C3, C4, C5 = features
        P3_in = C3
        P4_in = C4
        P5_in = C5
        P6_in = layers.Conv2D(
            num_channels, kernel_size=1, padding="same", name="resample_p6/conv2d"
        )(C5)
        P6_in = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name="resample_p6/bn"
        )(P6_in)
        # P6_in = BatchNormalization(freeze=freeze_bn, name='resample_p6/bn')(P6_in)
        P6_in = layers.MaxPooling2D(
            pool_size=3, strides=2, padding="same", name="resample_p6/maxpool"
        )(P6_in)
        P7_in = layers.MaxPooling2D(
            pool_size=3, strides=2, padding="same", name="resample_p7/maxpool"
        )(P6_in)
        P7_U = layers.UpSampling2D()(P7_in)
        P6_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode0/add")([P6_in, P7_U])
        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)
        P6_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode0/op_after_combine5",
        )(P6_td)
        P5_in_1 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode1/resample_0_2_6/conv2d",
        )(P5_in)
        P5_in_1 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn"
        )(P5_in_1)
        # P5_in_1 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode1/resample_0_2_6/bn')(P5_in_1)
        P6_U = layers.UpSampling2D()(P6_td)
        P5_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode1/add")([P5_in_1, P6_U])
        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)
        P5_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode1/op_after_combine6",
        )(P5_td)
        P4_in_1 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode2/resample_0_1_7/conv2d",
        )(P4_in)
        P4_in_1 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn"
        )(P4_in_1)
        # P4_in_1 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode2/resample_0_1_7/bn')(P4_in_1)
        P5_U = layers.UpSampling2D()(P5_td)
        P4_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode2/add")([P4_in_1, P5_U])
        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)
        P4_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode2/op_after_combine7",
        )(P4_td)
        P3_in = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode3/resample_0_0_8/conv2d",
        )(P3_in)
        P3_in = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn"
        )(P3_in)
        # P3_in = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode3/resample_0_0_8/bn')(P3_in)
        P4_U = layers.UpSampling2D()(P4_td)
        P3_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode3/add")([P3_in, P4_U])
        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)
        P3_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode3/op_after_combine8",
        )(P3_out)
        P4_in_2 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode4/resample_0_1_9/conv2d",
        )(P4_in)
        P4_in_2 = layers.BatchNormalization(
            momentum=MOMENTUM, epsilon=EPSILON, name=f"fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn"
        )(P4_in_2)
        # P4_in_2 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode4/resample_0_1_9/bn')(P4_in_2)
        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P3_out)
        P4_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode4/add")([P4_in_2, P4_td, P3_D])
        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)
        P4_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode4/op_after_combine9",
        )(P4_out)

        P5_in_2 = layers.Conv2D(
            num_channels,
            kernel_size=1,
            padding="same",
            name=f"fpn_cells/cell_{id}/fnode5/resample_0_2_10/conv2d",
        )(P5_in)
        P5_in_2 = layers.BatchNormalization(
            momentum=MOMENTUM,
            epsilon=EPSILON,
            name=f"fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn",
        )(P5_in_2)
        # P5_in_2 = BatchNormalization(freeze=freeze_bn, name=f'fpn_cells/cell_{id}/fnode5/resample_0_2_10/bn')(P5_in_2)
        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P4_out)
        P5_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode5/add")([P5_in_2, P5_td, P4_D])
        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)
        P5_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode5/op_after_combine10",
        )(P5_out)

        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P5_out)
        P6_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode6/add")([P6_in, P6_td, P5_D])
        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)
        P6_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode6/op_after_combine11",
        )(P6_out)

        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P6_out)
        P7_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode7/add")([P7_in, P6_D])
        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)
        P7_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode7/op_after_combine12",
        )(P7_out)

    else:
        P3_in, P4_in, P5_in, P6_in, P7_in = features
        P7_U = layers.UpSampling2D()(P7_in)
        P6_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode0/add")([P6_in, P7_U])
        P6_td = layers.Activation(lambda x: tf.nn.swish(x))(P6_td)
        P6_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode0/op_after_combine5",
        )(P6_td)
        P6_U = layers.UpSampling2D()(P6_td)
        P5_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode1/add")([P5_in, P6_U])
        P5_td = layers.Activation(lambda x: tf.nn.swish(x))(P5_td)
        P5_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode1/op_after_combine6",
        )(P5_td)
        P5_U = layers.UpSampling2D()(P5_td)
        P4_td = layers.Add(name=f"fpn_cells/cell_{id}/fnode2/add")([P4_in, P5_U])
        P4_td = layers.Activation(lambda x: tf.nn.swish(x))(P4_td)
        P4_td = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode2/op_after_combine7",
        )(P4_td)
        P4_U = layers.UpSampling2D()(P4_td)
        P3_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode3/add")([P3_in, P4_U])
        P3_out = layers.Activation(lambda x: tf.nn.swish(x))(P3_out)
        P3_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode3/op_after_combine8",
        )(P3_out)
        P3_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P3_out)
        P4_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode4/add")([P4_in, P4_td, P3_D])
        P4_out = layers.Activation(lambda x: tf.nn.swish(x))(P4_out)
        P4_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode4/op_after_combine9",
        )(P4_out)

        P4_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P4_out)
        P5_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode5/add")([P5_in, P5_td, P4_D])
        P5_out = layers.Activation(lambda x: tf.nn.swish(x))(P5_out)
        P5_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode5/op_after_combine10",
        )(P5_out)

        P5_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P5_out)
        P6_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode6/add")([P6_in, P6_td, P5_D])
        P6_out = layers.Activation(lambda x: tf.nn.swish(x))(P6_out)
        P6_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode6/op_after_combine11",
        )(P6_out)

        P6_D = layers.MaxPooling2D(pool_size=3, strides=2, padding="same")(P6_out)
        P7_out = layers.Add(name=f"fpn_cells/cell_{id}/fnode7/add")([P7_in, P6_D])
        P7_out = layers.Activation(lambda x: tf.nn.swish(x))(P7_out)
        P7_out = SeparableConvBlock(
            num_channels=num_channels,
            kernel_size=3,
            strides=1,
            name=f"fpn_cells/cell_{id}/fnode7/op_after_combine12",
        )(P7_out)
    return P3_out, P4_td, P5_td, P6_td, P7_out


class BoxNet(models.Model):
    def __init__(
        self,
        width,
        depth,
        num_anchors=9,
        separable_conv=True,
        freeze_bn=False,
        detect_quadrangle=False,
        **kwargs,
    ):
        super(BoxNet, self).__init__(**kwargs)
        self.width = width
        self.depth = depth
        self.num_anchors = num_anchors
        self.separable_conv = separable_conv
        self.detect_quadrangle = detect_quadrangle
        num_values = 9 if detect_quadrangle else 4
        options = {
            "kernel_size": 3,
            "strides": 1,
            "padding": "same",
            "bias_initializer": "zeros",
        }
        if separable_conv:
            kernel_initializer = {
                "depthwise_initializer": initializers.VarianceScaling(),
                "pointwise_initializer": initializers.VarianceScaling(),
            }
            options.update(kernel_initializer)
            self.convs = [
                layers.SeparableConv2D(filters=width, name=f"{self.name}/box-{i}", **options)
                for i in range(depth)
            ]
            self.head = layers.SeparableConv2D(
                filters=num_anchors * num_values, name=f"{self.name}/box-predict", **options
            )
        else:
            kernel_initializer = {
                "kernel_initializer": initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)
            }
            options.update(kernel_initializer)
            self.convs = [
                layers.Conv2D(filters=width, name=f"{self.name}/box-{i}", **options)
                for i in range(depth)
            ]
            self.head = layers.Conv2D(
                filters=num_anchors * num_values, name=f"{self.name}/box-predict", **options
            )
        self.bns = [
            [
                layers.BatchNormalization(
                    momentum=MOMENTUM, epsilon=EPSILON, name=f"{self.name}/box-{i}-bn-{j}"
                )
                for j in range(3, 8)
            ]
            for i in range(depth)
        ]
        # self.bns = [[BatchNormalization(freeze=freeze_bn, name=f'{self.name}/box-{i}-bn-{j}') for j in range(3, 8)]
        #             for i in range(depth)]
        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))
        self.reshape = layers.Reshape((-1, num_values))
        self.level = 0

    def call(self, inputs, **kwargs):
        feature, level = inputs
        for i in range(self.depth):
            feature = self.convs[i](feature)
            feature = self.bns[i][self.level](feature)
            feature = self.relu(feature)
        outputs = self.head(feature)
        outputs = self.reshape(outputs)
        self.level += 1
        return outputs


class ClassNet(models.Model):
    def __init__(
        self,
        width,
        depth,
        num_classes=20,
        num_anchors=9,
        separable_conv=True,
        freeze_bn=False,
        **kwargs,
    ):
        super(ClassNet, self).__init__(**kwargs)
        self.width = width
        self.depth = depth
        self.num_classes = num_classes
        self.num_anchors = num_anchors
        self.separable_conv = separable_conv
        options = {
            "kernel_size": 3,
            "strides": 1,
            "padding": "same",
        }
        if self.separable_conv:
            kernel_initializer = {
                "depthwise_initializer": initializers.VarianceScaling(),
                "pointwise_initializer": initializers.VarianceScaling(),
            }
            options.update(kernel_initializer)
            self.convs = [
                layers.SeparableConv2D(
                    filters=width,
                    bias_initializer="zeros",
                    name=f"{self.name}/class-{i}",
                    **options,
                )
                for i in range(depth)
            ]
            self.head = layers.SeparableConv2D(
                filters=num_classes * num_anchors,
                bias_initializer=PriorProbability(probability=0.01),
                name=f"{self.name}/class-predict",
                **options,
            )
        else:
            kernel_initializer = {
                "kernel_initializer": initializers.RandomNormal(mean=0.0, stddev=0.01, seed=None)
            }
            options.update(kernel_initializer)
            self.convs = [
                layers.Conv2D(
                    filters=width,
                    bias_initializer="zeros",
                    name=f"{self.name}/class-{i}",
                    **options,
                )
                for i in range(depth)
            ]
            self.head = layers.Conv2D(
                filters=num_classes * num_anchors,
                bias_initializer=PriorProbability(probability=0.01),
                name="class-predict",
                **options,
            )
        self.bns = [
            [
                layers.BatchNormalization(
                    momentum=MOMENTUM, epsilon=EPSILON, name=f"{self.name}/class-{i}-bn-{j}"
                )
                for j in range(3, 8)
            ]
            for i in range(depth)
        ]
        # self.bns = [[BatchNormalization(freeze=freeze_bn, name=f'{self.name}/class-{i}-bn-{j}') for j in range(3, 8)]
        #             for i in range(depth)]
        self.relu = layers.Lambda(lambda x: tf.nn.swish(x))
        self.reshape = layers.Reshape((-1, num_classes))
        self.activation = layers.Activation("sigmoid")
        self.level = 0

    def call(self, inputs, **kwargs):
        feature, level = inputs
        for i in range(self.depth):
            feature = self.convs[i](feature)
            feature = self.bns[i][self.level](feature)
            feature = self.relu(feature)
        outputs = self.head(feature)
        outputs = self.reshape(outputs)
        outputs = self.activation(outputs)
        self.level += 1
        return outputs


def efficientdet(
    phi,
    num_classes=20,
    num_anchors=9,
    weighted_bifpn=False,
    freeze_bn=False,
    score_threshold=0.01,
    detect_quadrangle=False,
    anchor_parameters=None,
    separable_conv=True,
):
    assert phi in range(7)
    input_size = image_sizes[phi]
    input_shape = (input_size, input_size, 3)
    image_input = layers.Input(input_shape)
    w_bifpn = w_bifpns[phi]
    d_bifpn = d_bifpns[phi]
    w_head = w_bifpn
    d_head = d_heads[phi]
    backbone_cls = backbones[phi]
    features = backbone_cls(input_tensor=image_input, freeze_bn=freeze_bn)
    if weighted_bifpn:
        fpn_features = features
        for i in range(d_bifpn):
            fpn_features = build_wBiFPN(fpn_features, w_bifpn, i, freeze_bn=freeze_bn)
    else:
        fpn_features = features
        for i in range(d_bifpn):
            fpn_features = build_BiFPN(fpn_features, w_bifpn, i, freeze_bn=freeze_bn)
    box_net = BoxNet(
        w_head,
        d_head,
        num_anchors=num_anchors,
        separable_conv=separable_conv,
        freeze_bn=freeze_bn,
        detect_quadrangle=detect_quadrangle,
        name="box_net",
    )
    class_net = ClassNet(
        w_head,
        d_head,
        num_classes=num_classes,
        num_anchors=num_anchors,
        separable_conv=separable_conv,
        freeze_bn=freeze_bn,
        name="class_net",
    )
    classification = [class_net([feature, i]) for i, feature in enumerate(fpn_features)]
    classification = layers.Concatenate(axis=1, name="classification")(classification)
    regression = [box_net([feature, i]) for i, feature in enumerate(fpn_features)]
    regression = layers.Concatenate(axis=1, name="regression")(regression)

    model = models.Model(
        inputs=[image_input], outputs=[classification, regression], name="efficientdet"
    )

    # apply predicted regression to anchors
    anchors = anchors_for_shape((input_size, input_size), anchor_params=anchor_parameters)
    anchors_input = np.expand_dims(anchors, axis=0)
    boxes = RegressBoxes(name="boxes")([anchors_input, regression[..., :4]])
    boxes = ClipBoxes(name="clipped_boxes")([image_input, boxes])

    # filter detections (apply NMS / score threshold / select top-k)
    if detect_quadrangle:
        detections = FilterDetections(
            name="filtered_detections", score_threshold=score_threshold, detect_quadrangle=True
        )([boxes, classification, regression[..., 4:8], regression[..., 8]])
    else:
        detections = FilterDetections(name="filtered_detections", score_threshold=score_threshold)(
            [boxes, classification]
        )

    prediction_model = models.Model(inputs=[image_input], outputs=detections, name="efficientdet_p")
    return model, prediction_model


if __name__ == "__main__":
    x, y = efficientdet(1)
