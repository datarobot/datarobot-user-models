name: vLLM Inference Server Example
type: inference
targetType: textgeneration

runtimeParameterDefinitions:
  - fieldName: model
    type: string
    defaultValue: meta-llama/Meta-Llama-3-8B-Instruct
    description: Name of the model to download from HuggingFace **or** path to pre-downloaded model.

  - fieldName: HuggingFaceToken
    type: credential
    credentialType: api_token
    description: |-
      Access Token from HuggingFace (https://huggingface.co/settings/tokens). Only
      required if the model was not downloaded in the `custom.py:load_model` function.

  - fieldName: max_tokens
    type: numeric
    defaultValue: 256
    description: max number of symbols in response

  - fieldName: system_prompt
    type: string
    defaultValue: You are a helpful AI assistant. Keep short answers of no more than 2 sentences.
    description: instructions to the model, to set the tone of model completions

  - fieldName: prompt_column_name
    type: string
    defaultValue: user_prompt
    description: column with user's prompt (each row is a separate completion request)
