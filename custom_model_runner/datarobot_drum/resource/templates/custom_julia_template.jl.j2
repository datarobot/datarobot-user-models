module Custom

using DataFrames
using CSV

export init, load_model, read_input_data, transform, score, post_process

"""
This file was autogenerated by: {{gen_command}}
Generation date: {{gen_date}}

Note: this is an example of custom.jl file.
    Below are all the hooks you can use to provide your own implementation.
    All hooks are currently commented out so uncomment a hook function in 
    order to use it.
"""

"""
    init(code_dir) 

    This hook can be implemented to adjust logic in the training and scoring mode.
    init is called once the code is started.

    # arguments
    - code_dir - code folder passed in --code_dir argument

    # returns
    - nothing
"""
function init(code_dir::String)
    return nothing
end

"""
    load_model(code_dir)

    load_model hook provides a way to implement model loading your self.
    This function should return an object that represents your model. This object will
    be passed to the predict hook for performing predictions.
    This hook can be used to load supported models if your model has multiple artifacts, or
    for loading models that drum does not natively support

    # arguments
    - `code_dir`: the directory to load serialized models from

    # returns
    - Object containing the model - the predict hook will get this object as a parameter
"""
function load_model(code_dir)
    return "dummy"
end 

"""
    read_input_data(input_binary_data)

    This hook can be implemented to modify reading input data, e.g. decode using custom charset.

    This function should return a dataframe, which will be passed into the transform hook.
    If it returns something other than a DF, you'll need to write your own score method.

    # arguments 
    - `input_binary_data` - input data as bytes in string format
    
    # returns
    - DataFrames.DataFrame
    """
function read_input_data(input_binary_data)
    data = CSV.read(
        IOBuffer(input_binary_data),
        DataFrames.DataFrame,
        delim=","
    )
    return data
end

"""

    transform(data, model)

    This hook can be implemented to adjust logic in the scoring mode.

    Intended to apply transformations to the prediction data before making predictions.
    This is most useful if drum supports the model's library, but your model requires additional
    data processing before it can make predictions

    # arguments
    - `data` - input data
    - `model` - s the deserialized model loaded by drum or by load_model hook , if supplied

    # returns 
    - `T`
"""
function transform(data, model)
    return data
end

"""
    score(data, model; kwargs...)

    This hook can be implemented to adjust logic in the scoring mode.

    This method should return predictions as a dataframe with the following format:

    Binary Classification:
    Must have columns for each class label with floating-point class probabilities as values.
    Each row should sum to 1.0

    Regression:
    Must have a single column called "Predictions" with numerical values

    This hook is only needed if you would like to use drum with a framework not natively
    supported by the tool.

    # arguments
    - `data` - data to make predictions against
    - `model` - is the deserialized model loaded by drum or by load_model hook, if supplied

    # keywords
    - `kwargs` - additional keyword arguments to the function. If model is binary classification,
    positive_class_label and negative_class_label will be provided in kwargs. If the model is multiclass
    classification (at least 3 classes), a class_labels list will be provided as a parameter.

    # returns 
    - DataFrame

"""
function score(data, model; kwargs)
    m,n = size(data)
    predictions = repeat([0.5], m)
    return DataFrames.DataFrame(Predictions = predictions)
end

"""
    post_process(predictions, model)

    This hook can be implemented to adjust logic in the scoring mode.

    This method should return predictions as a dataframe with the following format:

    Binary Classification:
    Must have columns for each class label with floating- point class probabilities as values.
        Each row should sum to 1.0

    Regression:
    Must have a single column called `Predictions` with numerical values

    This method is only needed if your model's output does not match the above expectations

    # arguments
    - predictions: DataFrame - s the dataframe of predictions produced by `cmrun` or by the
    `score` hook, if supplied
    - model - the deserialized model loaded by `cmrun` or by `load_model`, if supplied

    # returns
    - DataFrames.DataFrame
"""
function post_process(predictions, model)
    return predictions
end 

end